{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Importando bibliotecas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Carregando YOLO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', source='github',\n",
    "                       pretrained=True, verbose=False)\n",
    "model.cuda('cuda:0')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Informando arquivos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pode receber vídeo, webcam (0), link para câmera...\n",
    "filename = r'videos\\vid_21-12_intervalo2.avi'\n",
    "\n",
    "imgDB_path = r'output/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Salvamento de dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = cv2.VideoWriter('output.avi', \n",
    "                        cv2.VideoWriter_fourcc(*'MJPG'),\n",
    "                        5, (1200, 720))\n",
    "\n",
    "\n",
    "crowd_cache = []\n",
    "\n",
    "db = mysql.connector.connect(\n",
    "                host=\"localhost\",\n",
    "                user=\"root\",\n",
    "                passwd=\"lu_iz\",\n",
    "                database=\"crowd_detection\"\n",
    "            )\n",
    "            \n",
    "mycursor = db.cursor()\n",
    "mycursor.execute('SET autocommit = ON;')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passo a passo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_people(X, Y):\n",
    "    agglomerations = [[0]]\n",
    "    if len(X) > 0 or len(Y) > 0:\n",
    "        print(\"\\nPares aglomerados: \")\n",
    "        print(X, Y)\n",
    "        for i, j in zip(X, Y):\n",
    "            for k in agglomerations:\n",
    "                for l in k:\n",
    "                    if i in k:\n",
    "                        if j not in k:\n",
    "                            k.append(j)\n",
    "                            break\n",
    "                    elif j in k:\n",
    "                        if i not in k:\n",
    "                            k.append(i)\n",
    "                            break\n",
    "                    else:\n",
    "                        for k in agglomerations:\n",
    "                            if i in k or j in k:\n",
    "                                break\n",
    "                        else:\n",
    "                            agglomerations.append([i])\n",
    "                            break\n",
    "\n",
    "    return agglomerations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Passo 5: atribuição de IDs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_tracking(groups, centroids, crowd_cache):\n",
    "    \"\"\" Tracks groups by frames returning new or increased groups.\n",
    "\n",
    "    ID assignment: for to each group, assigns it the ID of the closest\n",
    "    one of the previous frame. In case it runs out of past groups to\n",
    "    compare with, create a new ID.\n",
    "\n",
    "    New groups: if a new ID is created or, one of the past groups has \n",
    "    grown in size, the respective group is added to crop_groups list.\"\"\"\n",
    "\n",
    "    # Calculate the average coordinates (centroids) of each group\n",
    "    grpCentroids = []\n",
    "    for group in groups: # groups = [[0, 2, 3], [1, 4]] [[0]]\n",
    "        # Consider only the coordinates of the people in the group\n",
    "        peopleCoords = [centroids[person] for person in group]\n",
    "        # Calculate the mean of all coordinates in that group\n",
    "        centroid = np.mean(peopleCoords, axis=0)\n",
    "        # Append them to the list with the coordinates of all groups\n",
    "        grpCentroids.append(centroid)\n",
    "\n",
    "    \n",
    "    print('Coordenadas médias das aglomerações: ')\n",
    "    print(grpCentroids)\n",
    "\n",
    "    # Assign the ID's of the last group coordinates or create new ones\n",
    "    '''Now, we need to loop through the groups, and, for each one,\n",
    "    assign it the ID of nearest past centroid. In case there's no other\n",
    "    centroid to compare with, we need to create a new ID.'''\n",
    "    for i in range(len(grpCentroids)):\n",
    "        stopped = False\n",
    "        # Check for past group centroids to compare with.\n",
    "        if i < len(crowd_cache):\n",
    "            '''Here, we don't start the distance measureament from the beggining\n",
    "            of crowd_cache[], but by the next position from where we've \n",
    "            last added a group centroid of the current frame.'''\n",
    "            clst = i\n",
    "            for j in range(i+1, len(crowd_cache)):\n",
    "                eclDist = np.linalg.norm(grpCentroids[i] - crowd_cache[j]['centroid'])\n",
    "                srtst_eclDist = np.linalg.norm(grpCentroids[i] - crowd_cache[clst]['centroid'])\n",
    "                clst = j if eclDist < srtst_eclDist else clst\n",
    "\n",
    "            # If the distance between the centroids is 0, it means it has stopped,\n",
    "            # probably because the group has ceased to move. Therefore, we can mark \n",
    "            # them not to update them.\n",
    "            dist = np.linalg.norm(grpCentroids[i] - crowd_cache[clst]['centroid'])\n",
    "            if dist == 0:\n",
    "                stopped = True\n",
    "\n",
    "            # ID assignment\n",
    "            identity = crowd_cache[clst]['id']\n",
    "\n",
    "            # Delete the closest past centroid to update the list with the ith group\n",
    "            # afterwards.\n",
    "            del crowd_cache[clst]\n",
    "        else:\n",
    "            '''If there are no past centroids to compare with, that means we have\n",
    "            new groups and we must create new ID's for them. Also, we need to pass\n",
    "            that information to crop_groups so that we can do the cropping.'''\n",
    "\n",
    "            mycursor.execute(\"SELECT MAX( crowd_id ) FROM crowd_records;\")\n",
    "            id = mycursor.fetchone()[0]\n",
    "            \n",
    "            identity = id + 1 if id is not None else 0\n",
    "            print(50*\"=\", f\"\\nNovo grupo criado: grupo {i}!\\n\", 50*\"=\")\n",
    "\n",
    "        \n",
    "        # Pass the ID to the groups to do cropping with new groups later on\n",
    "        groups[i] = {'id' : identity,\n",
    "                     'people' : groups[i]}\n",
    "\n",
    "        # update crowd_cache for the next group tracking, except if\n",
    "        # the group has stopped.\n",
    "        if stopped:\n",
    "            pass\n",
    "        else:\n",
    "            group = {'id' : identity,\n",
    "                     'centroid' : grpCentroids[i],\n",
    "                     'size' : len(groups[i]['people'])}\n",
    "            crowd_cache.insert(i, group)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Passo 4: Calcular distâncias entre as pessoas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(point1, point2):\n",
    "    '''Calculate usual distance.'''\n",
    "    x1, y1 = point1\n",
    "    x2, y2 = point2\n",
    "    return np.linalg.norm([x1 - x2, y1 - y2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Passo 3: Aplicar transformação de perspectiva nas centroides**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_bird(centers, M):\n",
    "    '''Apply the perpective to the bird's-eye view.'''\n",
    "    centers = [cv2.perspectiveTransform(np.float32([[center]]), M) for center in centers.copy()]\n",
    "    centers = [list(center[0, 0]) for center in centers.copy()]\n",
    "    return centers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Passos 1, 2 e 6: detecção das pessoas, cálculo das centroides e salvamento dos dados**\n",
    "A segunda função chama a primeira, que é responsável por aplicar as demais durante o processamento da imagem (frame)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bird_detect_people_on_frame(img, confidence, distance, width, height, prevCenters,\n",
    "                                region=None, dst=None):\n",
    "    results = model([img[:, :, ::-1]])  # Pass the frame through the model and get the boxes\n",
    "\n",
    "    xyxy = results.xyxy[0].cpu().numpy()  # xyxy are the box coordinates\n",
    "    #          x1 (pixels)  y1 (pixels)  x2 (pixels)  y2 (pixels)   confidence        class\n",
    "    # tensor([[7.47613e+02, 4.01168e+01, 1.14978e+03, 7.12016e+02, 8.71210e-01, 0.00000e+00],\n",
    "    #         [1.17464e+02, 1.96875e+02, 1.00145e+03, 7.11802e+02, 8.08795e-01, 0.00000e+00],\n",
    "    #         [4.23969e+02, 4.30401e+02, 5.16833e+02, 7.20000e+02, 7.77376e-01, 2.70000e+01],\n",
    "    #         [9.81310e+02, 3.10712e+02, 1.03111e+03, 4.19273e+02, 2.86850e-01, 2.70000e+01]])\n",
    "\n",
    "    xyxy = xyxy[xyxy[:, 4] >= confidence]  # Filter desired confidence\n",
    "    xyxy = xyxy[xyxy[:, 5] == 0]  # Consider only people\n",
    "    xyxy = xyxy[:, :4]\n",
    "\n",
    "    print('XYXY coords: ')\n",
    "    print(xyxy)\n",
    "\n",
    "    # Calculate the centers of the circles\n",
    "    # They will be the centers of the bottom of the boxes\n",
    "    centers = []\n",
    "    for x1, y1, x2, y2 in xyxy:\n",
    "        center = [np.mean([x1, x2]), y2]\n",
    "        centers.append(center)\n",
    "\n",
    "    print('\\nCentroides: ')\n",
    "    print(centers)\n",
    "\n",
    "    # We create two transformations\n",
    "    if region is None:\n",
    "        # The region on the original image\n",
    "        region = np.float32([[144, 130], [222, 129], [width, height], [0, height]])\n",
    "    else:\n",
    "        region = np.float32(region)\n",
    "    if dst is None:\n",
    "        # The rectangle we want the image to be trasnformed to\n",
    "        dst = np.float32([[0, 0], [width, 0], [width, 3*width], [0, 3*width]])\n",
    "    else:\n",
    "        dst = np.float32(dst)\n",
    "    # The first transformation is straightforward: the region to the rectangle\n",
    "    # as thin the example before\n",
    "    M = cv2.getPerspectiveTransform(region, dst)\n",
    "    print('Matriz de transformação: ')\n",
    "    print(M)\n",
    "    \n",
    "    # The second transformation is a trick, because, using the common transformation,\n",
    "    # we can't draw circles at left of the region.\n",
    "    # This way, we flip all things and draw the circle at right of the region,\n",
    "    # because we can do it.\n",
    "    region_flip = region*np.float32([-1, 1]) + np.float32([width, 0])\n",
    "    dst_flip = dst*np.float32([-1, 1]) + np.float32([width, 0])\n",
    "    M_flip = cv2.getPerspectiveTransform(region_flip, dst_flip)\n",
    "\n",
    "    # Convert to bird\n",
    "    # Now, the center of the circles will be positioned on the rectangle\n",
    "    # and we can calculate the usual distance\n",
    "    bird_centers = convert_to_bird(centers, M)\n",
    "    print('\\nCoordenadas na visão de pássaro: ')\n",
    "    print(bird_centers)\n",
    "\n",
    "    # We verify if the circles colide\n",
    "    # If so, they will be red\n",
    "    colors = ['green']*len(bird_centers)\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i in range(len(bird_centers)):\n",
    "        x, y, w, h = xyxy[i]\n",
    "        x = int(x)\n",
    "        y = int(y)\n",
    "        w = int(w)\n",
    "        h = int(h)\n",
    "        cv2.rectangle(img, (x,y), (w, h), (0, 0, 255), 2)\n",
    "        for j in range(i+1, len(bird_centers)):\n",
    "            dist = calculate_distance(bird_centers[i], bird_centers[j])\n",
    "            print(f'Distância entre pessoa {i} e pessoa {j}: {dist}')\n",
    "            if dist < distance:\n",
    "                colors[i] = 'red'\n",
    "                X.append(i)\n",
    "                colors[j] = 'red'\n",
    "                Y.append(j)\n",
    "    \n",
    "    groups = group_people(X, Y)\n",
    "\n",
    "    if len(groups) > 0:\n",
    "        print(\"Groups organized: \", groups)\n",
    "    \n",
    "    print('\\nCrowd_cache passado: ', crowd_cache)\n",
    "\n",
    "    # We draw the circles\n",
    "    # Because we have two transformation, we will start with two empty\n",
    "    # images (\"overlay\" images) to draw the circles\n",
    "    overlay = np.zeros((3*width, 4*width, 3), np.uint8)\n",
    "    # overlay[:, :, :] = 200\n",
    "    overlay_flip = np.zeros((3*width, 4*width, 3), np.uint8)\n",
    "    # overlay_flip[:, :, :] = 200\n",
    "    for i, bird_center in enumerate(bird_centers):\n",
    "        if colors[i] == 'green':\n",
    "            color = (0, 255, 0)\n",
    "        else:\n",
    "            color = (0, 0, 255)\n",
    "        x, y = bird_center\n",
    "        x = int(x)\n",
    "        y = int(y)\n",
    "        if x >= int(distance/2+15/2):\n",
    "            # If it's the case the circle is inside or at right of our region\n",
    "            # we can use the normal overlay image\n",
    "            overlay = cv2.circle(overlay, (x, y), int(distance/2),\n",
    "                                  color, 15, lineType=cv2.LINE_AA)\n",
    "        else:\n",
    "            # If the circle is at left of the region,\n",
    "            # we draw the circle inverted on the other overlay image\n",
    "            x = width - x\n",
    "            overlay_flip = cv2.circle(overlay_flip, (x, y), int(distance/2),\n",
    "                                  color, 15, lineType=cv2.LINE_AA)\n",
    "\n",
    "    # We apply the inverse transformation to the overlay\n",
    "    overlay = cv2.warpPerspective(overlay, M, (width, height),\n",
    "                                  cv2.INTER_NEAREST, cv2.WARP_INVERSE_MAP)\n",
    "    cv2.imwrite(\"overlays\\overlay.png\", overlay)\n",
    "\n",
    "    # We apply the inverse of the other transformation to the other overlay\n",
    "    overlay_flip = cv2.warpPerspective(overlay_flip, M_flip, (width, height),\n",
    "                                       cv2.INTER_NEAREST, cv2.WARP_INVERSE_MAP)\n",
    "    # Now we \"unflip\" what the second overlay\n",
    "    overlay_flip = cv2.flip(overlay_flip, 1)\n",
    "    cv2.imwrite(\"overlays\\overlay_flip.png\", overlay_flip)\n",
    "\n",
    "    # We add all images\n",
    "    img = cv2.addWeighted(img, 1, overlay, 1, 0)\n",
    "    img = cv2.addWeighted(img, 1, overlay_flip, 1, 0)\n",
    "\n",
    "    # Find new or altered groups to crop\n",
    "    if len(groups[0]) > 1:\n",
    "        group_tracking(groups, bird_centers, crowd_cache)\n",
    "        print('\\nGrupos: ')\n",
    "        print(groups)\n",
    "        # print(\"Groups to crop: \", croppingGrps)\n",
    "        # To-do: Store the size of each group, followed by the date and time.\n",
    "        # Here, groups will have the same time, so that we can know, from \n",
    "        # data, that they are correlated\n",
    "        time = dt.datetime.now()\n",
    "\n",
    "        sizes = []\n",
    "        ids = []\n",
    "        for group in groups:\n",
    "            ids.append(group['id'])\n",
    "            sizes.append(len(group['people']))\n",
    "\n",
    "        # print(\"Crowds detected!\")\n",
    "        # print(\"Sizes: \", sizes)\n",
    "        imgName = time.strftime('%y%m%d_%H%M%S')\n",
    "        cv2.imwrite(imgDB_path+imgName+'.jpg', img)\n",
    "\n",
    "        d = {\n",
    "            'crowd_id': ids,\n",
    "            'size' : sizes,\n",
    "            'rec_time': time,\n",
    "            'image': imgName\n",
    "        }\n",
    "        \n",
    "        data = pd.DataFrame(data=d)\n",
    "        print('\\n')\n",
    "        print(data)\n",
    "        connection = create_engine('mysql+pymysql://root:lu_iz@localhost:3306/crowd_detection')\n",
    "        data.to_sql(con=connection, name=\"crowd_records\", if_exists='append', index=False)\n",
    "\n",
    "    else:\n",
    "        crowd_cache.clear()\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Passo 7: exibição da imagem após o processamento**\n",
    "Também responsável por chamar a função de seleção da região de transformação e a bird_detect_people_on_frame(), que faz o processamento da imagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bird_detect_people_on_video(filename, confidence=0.9, distance=1600, save=False, counter_value=1, region=None):\n",
    "    # Capture video\n",
    "    cap = cv2.VideoCapture(filename)\n",
    "\n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    if region is None:\n",
    "        from utils import points\n",
    "        region = points.capture_points(0, w_size=(1200, 720))\n",
    "    \n",
    "    counter = counter_value\n",
    "    while cap.isOpened():\n",
    "        # Read frame\n",
    "        ret, frame = cap.read()\n",
    "        frame= cv2.resize(frame,(1200, 720),interpolation=cv2.INTER_CUBIC)\n",
    "        width, height = (1200, 720)\n",
    "\n",
    "        print()\n",
    "        if cv2.waitKey(30) & 0xFF == ord('.'):\n",
    "            break\n",
    "            \n",
    "        cv2.imwrite('img-test1.png', frame)\n",
    "    \n",
    "        if ret == True:\n",
    "            counter -= 1\n",
    "            if counter == 0:\n",
    "                # Detect people as a bird\n",
    "                frame = bird_detect_people_on_frame(frame, confidence, distance,\n",
    "                                                    width, height, crowd_cache, region=region)\n",
    "                counter = counter_value\n",
    "            # Write frame to new video\n",
    "            output.write(frame) if save == True else 0\n",
    "\n",
    "            # Display frame\n",
    "            cv2.imshow(\"cam-mov\",frame)\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    # Release everything if job is finished\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Teste em imagem**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../demonstration/img-test.png'\n",
    "img = cv2.imread(filename)\n",
    "img = cv2.resize(img, (1200, 720),interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XYXY coords: \n",
      "[[     557.71      209.69      719.13      647.64]\n",
      " [     718.74      210.87      817.12      632.01]\n",
      " [     647.76      202.42      732.04      600.17]]\n",
      "\n",
      "Centroides: \n",
      "[[638.42053, 647.6394], [767.933, 632.00543], [689.8992, 600.1681]]\n",
      "Matriz de transformação: \n",
      "[[     4.9678     -18.377      5035.6]\n",
      " [    -8.7446     -27.221       16751]\n",
      " [ 8.9877e-05  -0.0056565           1]]\n",
      "\n",
      "Coordenadas na visão de pássaro: \n",
      "[[1417.675, 2479.4883], [1102.8859, 2860.6255], [1100.0851, 2408.846]]\n",
      "Distância entre pessoa 0 e pessoa 1: 494.32562255859375\n",
      "Distância entre pessoa 0 e pessoa 2: 325.3516845703125\n",
      "Distância entre pessoa 1 e pessoa 2: 451.7882080078125\n",
      "\n",
      "Pares aglomerados: \n",
      "[0, 0, 1] [1, 2, 2]\n",
      "Groups organized:  [[0, 1, 2]]\n",
      "\n",
      "Crowd_cache passado:  []\n",
      "Coordenadas médias das aglomerações: \n",
      "[array([     1206.9,        2583], dtype=float32)]\n",
      "================================================== \n",
      "Novo grupo criado: grupo 0!\n",
      " ==================================================\n",
      "\n",
      "Grupos: \n",
      "[{'id': 2, 'people': [0, 1, 2]}]\n",
      "\n",
      "\n",
      "   crowd_id  size                   rec_time          image\n",
      "0         2     3 2023-08-22 15:23:53.235501  230822_152353\n"
     ]
    }
   ],
   "source": [
    "region = [[577, 430], [384, 492], [911, 713], [1032, 553]]\n",
    "img = bird_detect_people_on_frame(img, 0.5, 1800, 1200, 720, crowd_cache, region)\n",
    "\n",
    "cv2.imshow('Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Inferência em vídeo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r'Testes\\vid_21-12_intervalo1.avi'\n",
    "region = [[577, 430], [384, 492], [911, 713], [1032, 553]]\n",
    "bird_detect_people_on_video(filename, confidence=0.5, distance=1800, save=True, counter_value=10, region=region)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d594d97deb58b79cc7878229b4f849dcac020adc012f4c502af840c716ab4bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
